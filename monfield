#!/bin/bash

# NAME: Monfield
#
# DESCRIPTION: monfield is a tool for automating the update of a specific
# field in specific record. The fields to query by and to update are read
# from a CSV file, and the updates are chunked into a number of JavaScript
# files, and then are executed on a remote mongo instance.
#
# AUTHOR: Mohammad Matini <mohammad.matini@outlook.com>
# COPYRIGHT: Workiom Inc. (2020)
# LICENSE: GPLv3
#

set -o errexit -o pipefail -o noclobber
shopt -s inherit_errexit

cat <<EOF

================================================================

           ┏┳┓┏━┓┏┓╻┏━╸╻┏━╸╻  ╺┳┓   ┏┳┓╻┏━╸┏━┓┏━┓╺┳╸┏━╸
           ┃┃┃┃ ┃┃┗┫┣╸ ┃┣╸ ┃   ┃┃   ┃┃┃┃┃╺┓┣┳┛┣━┫ ┃ ┣╸
           ╹ ╹┗━┛╹ ╹╹  ╹┗━╸┗━╸╺┻┛   ╹ ╹╹┗━┛╹┗╸╹ ╹ ╹ ┗━╸

                   Mongodb Field Migration Tool

    AUTHOR:     Mohammad Matini <mohammad.matini@outlook.com>
    MAINTAINER: Mohammad Matini <mohammad.matini@outlook.com>
    COPYRIGHT:  Workiom Inc. (2020)

================================================================

EOF

function print_usage () {
    cat <<EOF

    USAGE:

        monfield [REQUIRED-ARGUMENTS] [OPTIONS]


    DESCRIPTION:

        monfield is a tool for automating the update of a specific field in
        specific record. The fields to query by and to update are read from
        a CSV file, and the updates are chunked into a number of JavaScript
        files, and then are executed on a remote mongo instance.


    REQUIRED ARGUMENTS:

        --hostname                      URL for the database, as host:port
        --authentication-database       authentication database
        --username                      username to authenticate as
        --database-name                 database in which the migration will run
        --collection-name               collection in which the migration will run
        --migration-file                CSV file that contains the field definitions
        --output-js-folder              path where the JS batch scripts will be
                                        created. The scripts will be executed at
                                        the end if --dryrun was not supplied.
                                        The folder must not exist, as it will be
                                        created by this script.


    OPTIONS:

        -h, --help                      print this help message
        --dryrun                        print the mongo scripting calls instead
                                        of executing them
        --query-value-constructor       constructor name to be called on every
                                        query value, e.g. passing ObjectId will
                                        call ObjectId("query-value") on query
                                        values (Not passing this option means
                                        that all query values are passed
                                        literally)
        --update-value-constructor      constructor name to be called on every
                                        update value e.g. passing ISODate will
                                        call ISODate("update-value") on update
                                        values (Not passing this option means
                                        that all query values are passed
                                        literally)


    MIGRATION FILE:

        The migration file is a CSV file which is structured as follows:

            query-field,update-field
            query-value,update-value
            query-value,update-value
            query-value,update-value
            ...

        For each row containing a [query-value]-[update-value] pair, an
        update is executed; we find records where [query-field] is
        [query-value] and set their [update-field] to [update-value].

EOF
}

MAX_UPDATES_PER_BATCH=1000

function check_arguments () {
    if [ -z "$1" ]; then
        echo "    ERROR! Missing database hostname! Aborting!"
        print_usage
        exit 1
    fi

    if [ -z "$2" ]; then
        echo "    ERROR! Missing authentication database name! Aborting!"
        print_usage
        exit 1
    fi

    if [ -z "$3" ]; then
        echo "    ERROR! Missing username! Aborting!"
        print_usage
        exit 1
    fi

    if [ -z "$4" ]; then
        echo "    ERROR! Missing database name! Aborting!"
        print_usage
        exit 1
    fi

    if [ -z "$5" ]; then
        echo "    ERROR: Missing collection name! Aborting!"
        print_usage
        exit 1
    fi

    if [ -z "$6" ]; then
        echo "    ERROR: Missing migration file path! Aborting!"
        print_usage
        exit 1
    fi

    if [ ! -r "$6" ]; then
        echo "    ERROR: Migration file does not exist or unreadable! Aborting!"
        print_usage
        exit 1
    fi

    if [ -z "$7" ]; then
        echo "    ERROR: Missing output JS folder path! Aborting!"
        print_usage
        exit 1
    fi

    if [ -d "$7" ]; then
        echo
        echo "  ERROR: folder ($output_js_folder) already exists."
        echo "  Please delete the folder, or specify a new path."
        print_usage
        exit 1
    fi
}

function get_database_password () {
    read -r -p "  Enter database password: " -s password
    echo -n "$password"
}

function confirm_operation () {
    echo
    echo "  !!!! WARNING !!!! THIS OPERATION CAN NOT BE REVERSED"
    echo
    read -r -p "  Are you sure you want to continue? [y/n]: " -n 1 -r
    echo
    echo

    if [[ ! "$REPLY" =~ ^[Yy]$ ]]; then
        echo "    Operation cancled. Aborting..."
        echo
        exit 0
    fi
}

while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help) print_usage; exit 0 ;;
        --hostname) hostname="$2"; shift; shift ;;
        --authentication-database) auth_database_name="$2"; shift; shift ;;
        --username) username="$2"; shift; shift ;;
        --database-name) database_name="$2"; shift; shift ;;
        --collection-name) collection_name="$2"; shift; shift ;;
        --migration-file) migration_file="$2"; shift; shift ;;
        --query-value-constructor) query_value_constructor="$2"; shift; shift ;;
        --update-value-constructor) update_value_constructor="$2"; shift; shift ;;
        --output-js-folder) output_js_folder="$2"; shift; shift ;;
        --dryrun) dryrun=1; shift ;;
        *) echo "Unknown parameter: $1"; print_usage; exit 1 ;;
    esac
done

check_arguments "$hostname" "$auth_database_name" "$username" \
                "$database_name" "$collection_name" \
                "$migration_file" "$output_js_folder"

if [ -z $dryrun ]; then
    password=$(get_database_password)
else
    password=password-placeholder
fi

query_field=$(head -n 1 "$migration_file" | cut -d ',' -f 1 | sed '1s/^\xEF\xBB\xBF//') # remove BOM if it exists
update_field=$(head -n 1 "$migration_file" | cut -d ',' -f 2 | sed 's/\r$//') # remove DOS newlines

cat <<EOF


    HOSTNAME:        "$hostname"
    AUTH DATABASE:   "$auth_database_name"
    USERNAME:        "$username"

    DATABASE NAME:   "$database_name"
    COLLECTION NAME: "$collection_name"
    MIGRATION FILE:  "$migration_file"

    QUERY FIELD:    "$query_field"
    UPDATE FIELD:   "$update_field"

EOF

if [ ! -z $query_value_constructor ]; then
    echo "    Query Value Constructor:   $query_value_constructor"
fi

if [ ! -z $update_value_constructor ]; then
    echo "    Update Value Constructor:  $update_value_constructor"
fi

echo
echo

if [ -z $dryrun ]; then
    confirm_operation
fi

mkdir -p $output_js_folder

rows=$(tail -n +2 "$migration_file" | sed 's/\r$//') # remove DOS newlines
total_number_of_rows=$(echo "$rows" | wc -l)
number_of_processed_rows=0

while read -r row; do
    number_of_commas=$(echo $row | tr -d -c ',' | wc -c)
    if [ ! "$number_of_commas" -eq "1" ]; then
        echo "    ERROR: Wrong number of commans! in row: $row"
        echo "    monfield can only handle one comma per-line"
        echo "    it cannot handle escaped commans in CSV files"
        exit 1
    fi

    ((number_of_processed_rows=number_of_processed_rows + 1))
    number_of_batch_files=$(($number_of_processed_rows / $MAX_UPDATES_PER_BATCH))

    echo -en "\r    Currently Generating: $number_of_processed_rows/$total_number_of_rows rows \
(batch file no. $number_of_batch_files)"

    # use sed to change the CSV row to a JS array
    echo $row | sed "s/^/[\"/;s/,/\"],[\"/;s/$/\"],/" >> "$output_js_folder/$number_of_batch_files.js"

done <<< "$rows"

echo
echo

update_loop="
let collection = db.getCollection(\"$collection_name\")
for (let i = 0; i < data.length; i++) {
    collection.update(
        { \"$query_field\": { \$eq: $query_value_constructor(data[i][1]) } },
        { \$set: { \"$update_field\": $update_value_constructor(data[i][2]) } },
        { multi: true }
    );
}"

for (( file_number=0; file_number<=$number_of_batch_files; file_number++ )); do
	file_name="$output_js_folder/$file_number.js"

	# define data array and add the update loop to batch files
	sed -i '1s;^;let data = [\n;' $file_name
	echo "]" >> $file_name
	echo "$update_loop" >> $file_name

	command="
mongo -u $username -p $password $hostname/$database_name \
--authenticationDatabase $auth_database_name \
--eval 'load(\"$file_name\")'"

	echo ================================================================
	echo
	echo "    Executing Batch: $file_number/$number_of_batch_files"
	echo
        if [ -z $dryrun ];
        then eval "$command"
        else echo "$command"
        fi
        echo
done

echo
echo ================================================================
echo
echo "    Yay! Success!"
echo
